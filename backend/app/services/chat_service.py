import os
from openai import OpenAI
from dotenv import load_dotenv
from app.utils.gpt_prompt_manager import GPTPromptManager

# åŠ è¼‰ç’°å¢ƒè®Šæ•¸
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# å‰µå»º OpenAI å®¢æˆ¶ç«¯ï¼ˆæ–°ç‰ˆ SDK ç„¡éœ€ api_key åƒæ•¸ï¼‰
client = OpenAI()

# åˆå§‹åŒ– GPT Prompt ç®¡ç†å™¨
prompt_manager = GPTPromptManager()

class ChatService:
    def __init__(self, model="gpt-4o-mini"):
        """åˆå§‹åŒ– GPT èŠå¤©æœå‹™"""
        self.model = model

    def get_response(self, user_message: str, mode="default") -> str:
        """æ ¹æ“šæ¨¡å¼é¸æ“‡ä¸åŒçš„ GPT Promptï¼Œä¸¦ç²å– GPT å›æ‡‰"""
        try:
            print("ğŸš€ [DEBUG] é–‹å§‹è™•ç† GPT è«‹æ±‚...")
            print(f"ğŸ“ [User Message] {user_message}")
            print(f"ğŸ­ [Selected Mode] {mode}")

            # ç²å–æ¨¡å¼å°æ‡‰çš„ prompt
            system_prompt = prompt_manager.get_prompt(mode)
            print(f"ğŸ’¡ [System Prompt] {system_prompt}")

            # ç™¼é€è«‹æ±‚åˆ° OpenAI API
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200
            )

            # æª¢æŸ¥ API å›æ‡‰æ˜¯å¦æœ‰æ•ˆ
            if not response or not response.choices:
                raise ValueError("âŒ GPT å›æ‡‰ç„¡æ•ˆï¼Œè«‹æ±‚å¤±æ•—")

            # å–å¾— GPT å›æ‡‰
            ai_response = response.choices[0].message.content
            print(f"ğŸ¤– [GPT Response]: {ai_response}")

            return ai_response

        except Exception as e:
            print(f"âŒ [ERROR] GPT è™•ç†ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚è«‹ç¨å¾Œå†è©¦ã€‚"
